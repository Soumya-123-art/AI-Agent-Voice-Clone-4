# Day 4 - Teach-the-Tutor: Active Recall Coach

A voice-powered AI tutor built with LiveKit Agents and Murf AI TTS that helps you learn programming concepts through three interactive modes.

## ğŸ¯ Features

### Three Learning Modes

1. **Learn Mode** - The AI explains programming concepts with examples and analogies
2. **Quiz Mode** - Test your knowledge with interactive questions
3. **Teach Back Mode** - Explain concepts back to the AI and receive feedback

### Programming Concepts Covered

- Variables
- Loops (for and while)
- Functions
- Conditional Statements (if/else)
- Arrays and Lists

### Voice Integration

- **Murf AI Falcon TTS** - High-quality, natural-sounding voices
- **Deepgram STT** - Fast and accurate speech recognition
- **Google Gemini 2.5 Flash** - Intelligent conversation handling

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 18+
- LiveKit Server
- API Keys:
  - Murf AI API Key
  - Deepgram API Key
  - Google AI API Key

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/GhanshyamJha05/fourth_day_task_murf_api.git
cd fourth_day_task_murf_api
```

2. **Setup Backend**
```bash
cd backend
python -m venv .venv
.venv\Scripts\activate  # Windows
# or
source .venv/bin/activate  # Mac/Linux

pip install -e .
```

3. **Configure Environment Variables**

Create `backend/.env.local`:
```env
LIVEKIT_URL=ws://127.0.0.1:7880
LIVEKIT_API_KEY=devkey
LIVEKIT_API_SECRET=secret
GOOGLE_API_KEY=your_google_api_key
MURF_API_KEY=your_murf_api_key
DEEPGRAM_API_KEY=your_deepgram_api_key
```

4. **Setup Frontend**
```bash
cd ../frontend
npm install
```

Create `frontend/.env.local`:
```env
NEXT_PUBLIC_LIVEKIT_URL=ws://127.0.0.1:7880
LIVEKIT_API_KEY=devkey
LIVEKIT_API_SECRET=secret
```

### Running the Application

1. **Start LiveKit Server** (in project root)
```bash
./livekit-server.exe --dev
```

2. **Start Backend Agent** (in new terminal)
```bash
cd backend
.venv\Scripts\activate
python src/agent.py dev
```

3. **Start Frontend** (in new terminal)
```bash
cd frontend
npm run dev
```

4. **Open Browser**
Navigate to `http://localhost:3000` (or the port shown in terminal)

## ğŸ’¬ How to Use

1. **Connect** - Click the connect button and allow microphone access
2. **Greet** - Say "Hello" to start the conversation
3. **Choose Mode** - Say "I want to learn mode" or "quiz mode" or "teach back mode"
4. **Learn** - Interact with the AI tutor based on your chosen mode
5. **Switch Modes** - You can switch between modes anytime by asking

### Example Conversations

**Learn Mode:**
- "Explain variables to me"
- "Tell me about loops"
- "What are functions?"

**Quiz Mode:**
- "Quiz me on variables"
- "Ask me about loops"
- "Test my knowledge of conditionals"

**Teach Back Mode:**
- "I'll explain variables"
- "Let me teach you about functions"
- "I want to explain loops"

## ğŸ—ï¸ Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ agent.py          # Main agent logic with mode switching
â”‚   â”‚   â””â”€â”€ murf_tts.py       # Murf AI TTS integration
â”‚   â”œâ”€â”€ .env.local            # Backend environment variables
â”‚   â””â”€â”€ pyproject.toml        # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/                  # Next.js app directory
â”‚   â”œâ”€â”€ components/           # React components
â”‚   â”œâ”€â”€ .env.local           # Frontend environment variables
â”‚   â””â”€â”€ package.json         # Node dependencies
â”œâ”€â”€ shared-data/
â”‚   â””â”€â”€ day4_tutor_content.json  # Learning content
â””â”€â”€ livekit-server.exe       # LiveKit server binary
```

## ğŸ”§ Technical Details

### Backend Stack
- **LiveKit Agents SDK** - Voice agent framework
- **Murf AI Falcon** - Text-to-speech (Ryan voice)
- **Deepgram Nova-3** - Speech-to-text
- **Google Gemini 2.5 Flash** - LLM for conversation

### Frontend Stack
- **Next.js 15** - React framework
- **LiveKit Client SDK** - Real-time communication
- **Tailwind CSS** - Styling

## ğŸ“ Content File

The tutor content is stored in `shared-data/day4_tutor_content.json`:

```json
[
  {
    "id": "variables",
    "title": "Variables",
    "summary": "Variables are like labeled containers...",
    "sample_question": "What is a variable and why is it useful?"
  }
]
```

## ğŸ¤ Voice Configuration

The agent uses Murf AI Falcon voice:
- **Voice ID**: `en-US-ryan`
- **Style**: Conversational
- **Sample Rate**: 24kHz
- **Format**: WAV (Mono)

## ğŸ› Troubleshooting

### Agent Not Responding
- Check all three services are running (LiveKit, Backend, Frontend)
- Verify API keys in `.env.local` files
- Check browser console for errors

### No Audio
- Ensure microphone permissions are granted
- Check Murf API key is valid
- Verify audio output device is working

### Connection Issues
- Confirm LiveKit server is running on port 7880
- Check firewall settings
- Verify `.env.local` URLs match

## ğŸ“š Resources

- [LiveKit Agents Documentation](https://docs.livekit.io/agents/)
- [Murf AI API Documentation](https://murf.ai/api/docs)
- [Deepgram API Documentation](https://developers.deepgram.com/)
- [Google AI Documentation](https://ai.google.dev/)

## ğŸ† Challenge Completion

This project completes Day 4 of the Murf AI Voice Agent Challenge:
- âœ… Three learning modes (Learn, Quiz, Teach Back)
- âœ… Content-driven conversations
- âœ… Mode switching functionality
- âœ… Murf Falcon TTS integration
- âœ… Interactive voice interface

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ‘¤ Author

**Ghanshyam Jha**
- GitHub: [@GhanshyamJha05](https://github.com/GhanshyamJha05)
- Challenge: #MurfAIVoiceAgentsChallenge #10DaysofAIVoiceAgents

## ğŸ™ Acknowledgments

- Murf AI for the Voice Agent Challenge
- LiveKit for the amazing agents framework
- The open-source community

---

Built with â¤ï¸ for the Murf AI Voice Agent Challenge
